---
title: "Download metabolomics sample-level data"
author: "Pierre M Jean Beltran"
date: "7/16/2022"
output: html_document
---

```{r setup, include=FALSE,echo=F}
library(data.table)
library(MotrpacBicQC)
library(MotrpacRatTraining6moData)
library(dplyr)
library(testit)
library(usethis)
library(sinew)
library(devtools)
knitr::opts_chunk$set(echo = TRUE)
# set the current session
session_packages = c("knitr","kableExtra","limma","tidyverse","metap")
for (lib_name in session_packages){
  tryCatch({library(lib_name,character.only = T)}, error = function(e) {
    print(paste("Cannot load",lib_name,", please install"))
  })
}
```

In this document we prepare the PASS1B metabolomics animal data of MoTrPAC. The analysis flow is as follows:

1. Load the normalized and scaled data from the google cloud
2. Select either sample-center or non-centered data according to pre-computed KW test results

# 1. Load data

## 1.1 Set parameters and paths
```{r,message=FALSE,warning=FALSE,results="hide"}
#Specificy if data needs to be downloaded
download_from_bucket <- TRUE
# Specify the parameters required for the analysis
# This dir should have the motrpac-bic-norm-qc repo
repo_local_dir = "~/Projects/"
# Runnable command for gsutil
gsutil_cmd = "gsutil"
# Where should the data be downloaded to
# local_data_dir = "~/Projects/temp/metabolomics/"
local_data_dir = normalizePath("~/Projects/motrpac-bic-norm-qc/data/")
# Metabolomics original data freeze
targeted_buckets = c(
  "gs://motrpac-processed-mass_spectrometry/DF_PASS_20210731/pass1b-06/metabolomics-targeted/"
)
untargeted_buckets = c(
  "gs://motrpac-processed-mass_spectrometry/DF_PASS_20210731/pass1b-06/metabolomics-untargeted/"
)
# Path to the processed metabolomics data generated with pass1b_metabolomics_reimplementation.Rmd
bucket_analysis = "gs://mawg-data/pass1b-06/metabolomics/data/analysis_20210914"
bucket_normalized_tables = "gs://mawg-data/pass1b-06/metabolomics/data/normalized_tables_20210914/"
# Path to output bucket
mawg_dea_bucket = "gs://mawg-data/pass1b-06/metabolomics/dea/20210914/"
mawg_data_bucket = "gs://mawg-data/pass1b-06/metabolomics/data/merged_20210914/"
# Specify bucket and local path for the phenotypic data
# this path is internal to BIC - faster
# pheno_bucket = "gs://bic_data_analysis/pass1b/pheno_dmaqc/merged2020-06-12/"
# pheno_bucket = "gs://motrpac-internal-release2-results/pass1b-06/phenotype/"
pheno_bucket = "gs://mawg-data/pass1b-06/pheno_dmaqc/merged2021-09-09/"
# pheno_local_dir = "~/Projects/temp/pheno/"
pheno_local_dir = "~/Projects/motrpac-bic-norm-qc/data/20210731/"
#Suffix to be written with the output file - usually the date
output_suffix <- "20211006"
# Previous metabolomics analysis
metabolomics_analysis_previous <- "gs://mawg-data/pass1b-06/metabolomics/dea/deprecated_20201121/metabolomics_named_redundant_20210209.RData"
```

Specifiy the pipeline, metadata, and sample variables for the analysis.
```{r,eval=T,message=FALSE,warning=FALSE,results="hide"}
# Define technical and biological variables to be considered in the QC
pipeline_qc_cols = c("sample_order","raw_intensity","num_NAs")
biospec_cols = c("registration.sex",
                 "key.anirandgroup",
                 "registration.batchnumber",
                 "training.staffid",
                 "is_control",
                 "vo2.max.test.vo2_max_visit1", # this assumes that visit1's are aligned
                 "terminal.weight.mg",
                 "time_to_freeze",
                 "timepoint",
                 "bid",
                 "pid")
```

```{r,warning=F,results=F,message=F}
# load functions and libraries
source(paste0(repo_local_dir,"motrpac-bic-norm-qc/tools/gcp_functions.R"))
source(paste0(repo_local_dir,"motrpac-bic-norm-qc/tools/config_session.R"))
source(paste0(repo_local_dir,"motrpac-bic-norm-qc/tools/metabolomics_data_parsing_functions.R"))
```

## 1.2 Load phenotype data

```{r,message=FALSE,warning=FALSE,results="hide"}
# Add the pheno data
pheno_data = parse_pheno_data(pheno_bucket,
                              local_path = path.expand(pheno_local_dir),
                              remove_prev_files = TRUE,
                              GSUTIL_PATH=gsutil_cmd)
# add a tissue variable (for convenience)
pheno_data$viallabel_data$tissue = 
  pheno_data$viallabel_data$specimen.processing.sampletypedescription
# add the time to freeze variable ((for convenience))
pheno_data$viallabel_data$time_to_freeze = 
  pheno_data$viallabel_data$calculated.variables.frozetime_after_train - 
  pheno_data$viallabel_data$calculated.variables.deathtime_after_train
# some freeze times are negative because the tissues were taken
# before sacrifice time, zero these cases
pheno_data$viallabel_data$time_to_freeze = pmax(0,pheno_data$viallabel_data$time_to_freeze)
# add a binary is_control variable
pheno_data$viallabel_data$is_control = as.numeric(grepl("control",
                                                        pheno_data$viallabel_data$key.anirandgroup,
                                                        ignore.case = TRUE))
# add the timepoint as a number
# x - the text description of the group
get_numeric_timepoint <- function(x){
  v = rep(0,length(x))
  tps = c("Eight"=8,"Four"=4,"One"=1,"Two"=2)
  for(tp in names(tps)){
    v[grepl(paste0(tp,"-week"),x,perl = T,ignore.case = T)] = tps[tp]
  }
  return(v)
}
pheno_data$viallabel_data$timepoint = get_numeric_timepoint(
  pheno_data$viallabel_data$key.anirandgroup
)
```

## 1.3 Load metabolomics metadata

Load the parsed meta-data (from the cloud), required for all analyses presented here.
```{r}
if(download_from_bucket){
  for(targeted_bucket in targeted_buckets){
    rem_prev = targeted_bucket == targeted_buckets[1]
    obj = download_bucket_to_local_dir(targeted_bucket,
                                       path.expand(local_data_dir),
                                       remove_prev_files = rem_prev,
                                       GSUTIL_PATH=gsutil_cmd)
  }
  for(untargeted_bucket in untargeted_buckets){
    obj = download_bucket_to_local_dir(untargeted_bucket,
                                       path.expand(local_data_dir),
                                       remove_prev_files = FALSE,
                                       GSUTIL_PATH=gsutil_cmd)
  }
}
  
obj = list(
  downloaded_files = list.files(local_data_dir,
                                full.names = TRUE,
                                recursive = TRUE),
  local_path = local_data_dir
)
read_metabolomics_datasets_from_download_obj <- function(download_obj,verbose=T){
  downloaded_files = download_obj$downloaded_files
  local_path_reg = gsub("motrpac-bic-norm-qc\\\\","",download_obj$local_path)
  bucket_content = strsplit(downloaded_files,split=local_path_reg)
  bucket_content = lapply(bucket_content,function(x)
    strsplit(x[2],split=.Platform$file.sep)[[1]])
  # this is crucial: we assume that bucket structure is omics/tissue/assay/file, which
  # provides a vector of size five when splitting using "/
  bucket_content = bucket_content[sapply(bucket_content,length)==5]
  tissues = unlist(sapply(bucket_content,function(x)x[length(x)-2]))
  platforms = unlist(sapply(bucket_content,function(x)x[length(x)-1]))
  tissue_plarform_pairs = unique(cbind(tissues,platforms))
  tissue_plarform_pairs = 
    tissue_plarform_pairs[!grepl("qa-qc",tissue_plarform_pairs[,2]),]
  
  metabolomics_parsed_datasets = list()
  failed_buckets = c()
  for(j in 1:nrow(tissue_plarform_pairs)){
    tissue = tissue_plarform_pairs[j,1]
    platform = tissue_plarform_pairs[j,2]
    dataset_name = paste(c(tissue,platform),collapse=",")
    if(verbose){
      print(paste("parsing dataset:",dataset_name))
    }
    # read all datasets in current platform bucket - named and unnamed (if exists)
    # try reading first, if files are missing we will get an error
    datasets = NULL
    try({
      datasets = read_single_metabolomics_dataset_from_bucket(download_obj,tissue,platform)
    })
    if(is.null(datasets)){
      failed_buckets = c(failed_buckets,dataset_name)
      if(verbose){
        print(paste("Error, could not parse the data from:", dataset_name))
        print("Possible reason: missing data or metadata files, please revise")
      }
      next
    }
    if(verbose){print("done")}
    # add new datasets to the list of objects
    for(nn in names(datasets)){
        if(is.null(datasets[[nn]])){next}
        metabolomics_parsed_datasets[[paste(dataset_name,nn,sep=",")]] = datasets[[nn]]
    }
  }
  return(list(metabolomics_parsed_datasets=metabolomics_parsed_datasets,
              failed_buckets=failed_buckets))
}
metab_datasets = read_metabolomics_datasets_from_download_obj(download_obj = obj,
                                                              verbose = TRUE)
metabolomics_parsed_datasets = metab_datasets$metabolomics_parsed_datasets
# Download previous version of DEA results
get_single_file_from_bucket_to_local_dir(bucket = metabolomics_analysis_previous, 
                                         local_path = path.expand(local_data_dir), 
                                         remove_prev_files = FALSE,
                                         GSUTIL_PATH = gsutil_cmd)
load(file.path(local_data_dir, "metabolomics_named_redundant_20210209.RData"))
```


## 1.4 Load metabolomics normalized data
Load processed metabolomics data if required
```{r}
if(download_from_bucket){
  obj = download_bucket_to_local_dir(bucket_analysis,
                                     local_path=path.expand(local_data_dir),
                                     remove_prev_files = FALSE,
                                     GSUTIL_PATH=gsutil_cmd) 
  
  obj_normalized_tables = download_bucket_to_local_dir(bucket_normalized_tables,
                                              local_path=path.expand(local_data_dir),
                                              remove_prev_files = FALSE,
                                              GSUTIL_PATH=gsutil_cmd)
}
#Load Rdata files containing lists of the normalized metabolomics tables
load(Sys.glob(file.path(local_data_dir,"normalized_tables_*/targeted.Rdata"))) #targeted
load(Sys.glob(file.path(local_data_dir,"normalized_tables_*/untargeted_named.Rdata"))) #untargeted_named
```


# 2. Prepare metabolomics data

This section organizes and prepares metabolomics data for DEA.
1. Read KW test results to decide whether untargeted data used should be sample-centered or not.
2. Select appropriate tables for DEA:
    * Metabolomics targeted (>12 features): Table "3b imputed" - knn imputed, log2 transformed, feature ctr. Note: feature ctr has to be removed to preserve scale
  * Metabolomics targeted (<=12 features): Table "2" - log2 transformed
  * Metabolomics untargeted sample-centered: Table "2b2" - knn imputed, log2 transformed, sample centered
  * Metabolomics untargeted non-centered: Table "2" - knn imputed, log2 transformed
3. Read phenotype data matching samples in table
4. Extract tissue and assay names for each dataset
5. Remove Vena Cava Female 1 and 2 week samples, which are contaminated
6. Remove metabolites that have all missing values
7. Add feature metadata

```{r}
metab_data <- 
  
#1.Read KW test results------------------------------------------------------
read_tsv(Sys.glob(file.path(local_data_dir,
                   "analysis_*/pass1b-06_sample-ctr-decision-table-kw-summary.txt"))) %>%
  select(dataset,sample_ctr) %>%
  
#2. Select tables for DEA----------------------------------------------------
mutate(data_for_dea = map2(dataset,sample_ctr, function(dataset,sample_ctr){
  
  #Read targeted data
  if(grepl("metab_t",dataset)){
    
    #If dataset contains >12 features return table 3b imputed
    #However, remove feature scaling
    if("3b.imputed_named-convert2na-log2-featurectr-featurefilt-knn" %in%
       names(targeted[[dataset]])){
      
      scaled_data <- targeted[[dataset]][["3b.imputed_named-convert2na-log2-featurectr-featurefilt-knn"]]
      nonscaled_data <- targeted[[dataset]][["2_named-convert2na-log2"]]
      
      #Make sure non-scaled data has similar features as the scaled data
      nonscaled_data <- nonscaled_data[rownames(scaled_data),colnames(scaled_data)]
      
      data_median <- apply(nonscaled_data,1,median,na.rm=TRUE)
      # return_mat <- normalize_data*data_sd
      return_mat <- scaled_data+data_median
      return(return_mat)
      
      #Otherwise return table 2
    } else{
      return(targeted[[dataset]][["2_named-convert2na-log2"]])
    }
  
    #Read untargeted dataset
  } else {
    #If sample-centered data should be used return table 2b2
    if(sample_ctr == 1){
      return(untargeted_named[[dataset]][['2b2_named-featurefilt-knn-samplefilt-log2-samplectr']])
      
      #Otherwise, return table 2 
    } else {
      return(untargeted_named[[dataset]][["2_named-featurefilt-knn-samplefilt-log2"]])
    }
  }
  stop(paste0("Dataset ", dataset," in KW table not found!"))
})) %>%
  
#3. Read corresponding phenotype data-----------------------------------------
mutate(pheno = map(data_for_dea,function(x){
  
  pheno <- pheno_data$viallabel_data %>%
    select(viallabel,timepoint,registration.sex,is_control,bid,pid) %>%
    mutate(viallabel = as.character(viallabel)) %>%
    
    #Filter for samples in current dataset
    filter(viallabel %in% colnames(x)) %>%
    
    #Change sex integer to letter and add group variable
    mutate(sex = case_when(
      registration.sex == 1 ~ "F",
      registration.sex == 2 ~ "M"),
      tr_group = paste(timepoint,is_control,sep="_")
    )
  
  #Check if all samples have metadata
  not_found <- setdiff(x %>% colnames,pheno %>% .$viallabel)
  
  if(length(not_found) > 0){
    warning(paste("Samples not found in pheno data:",paste(not_found,collapse = ";")))
  }
  
  return(pheno)
  
})) %>%
  
#4. Extract tissue and assay names--------------------------------------------
separate(dataset,into=c("phase","tissue","ome","modality","platform"),
         sep="_") %>%
  mutate(assay_code = paste(ome,modality,platform,sep = "-")) %>%
  select(-ome,-modality,-platform,-phase, -sample_ctr) %>%
  select(tissue,assay_code,everything()) %>%
  
#5. Remove vena cava contaminated samples---------------------------------------
# First remove female 1w and 2w vena cava samples from data 
mutate(data_for_dea = pmap(list(tissue,data_for_dea,pheno), function(tissue,dat,pheno){
  if(tissue == "t65-aorta"){
    to_include <- pheno %>% filter(!((sex == "F") &
                                       (tr_group == "1_0" | tr_group == "2_0")))
    return(dat[,to_include$viallabel])
  } else {
    return(dat)
  }
}),
#Also remove from pheno metadata
pheno = map2(pheno,data_for_dea,function(pheno,dat){
  return(pheno[colnames(dat),])
})) %>%
  
#6. Remove metabolites that have all missing values
mutate(data_for_dea = map(data_for_dea,function(x){
  return(x[rowSums(is.na(x)) < ncol(x),])
})) %>%
  
#7. Add feature metadata --------------------------------------------------------
#Extract feature metadata
mutate(feature_metadata = pmap(list(tissue,assay_code,data_for_dea), function(tissue,assay_code,dat){
  id <- paste(tissue,assay_code,"named",sep = ",")
  metadata <- metabolomics_parsed_datasets[[id]][["row_annot"]]
  metadata <- metadata[rownames(dat),]
  if(sum(is.na(metadata$metabolite_name))>0){
    warning("Unable to find metadata for all features in: ", id)
  }
  return(metadata)
}))
```
# 3. Save results
```{r}
METAB_SAMPLE_DATA <- metab_data %>%
  rename(sample_data = data_for_dea)
# usethis::use_data(METAB_SAMPLE_DATA,overwrite=T)
# 
# # rename
# load("../../data/METAB_SAMPLE_DATA.rda")
METAB_SAMPLE_DATA_NESTED = METAB_SAMPLE_DATA
# usethis::use_data(METAB_SAMPLE_DATA_NESTED,overwrite=T)
# convert to nested list 
# load("../../data/METAB_SAMPLE_DATA_NESTED.rda")
data_list = list()
for(i in 1:nrow(METAB_SAMPLE_DATA_NESTED)){
  tissue_code = METAB_SAMPLE_DATA_NESTED$tissue[i]
  tissue = TISSUE_CODE_TO_ABBREV[[tissue_code]]
  platform = METAB_SAMPLE_DATA_NESTED$assay_code[i]
  data = as.data.frame(METAB_SAMPLE_DATA_NESTED$sample_data[i][[1]])
  data_list[[platform]][[tissue]] = data
}
METAB_NORM_DATA_NESTED = data_list
usethis::use_data(METAB_NORM_DATA_NESTED,overwrite=T)
```

# 4. Make metabolite-to-RefMet map from DEA
```{r}
load("../../data/METAB_SAMPLE_DATA_NESTED.rda")
load_all("../../../MotrpacRatTraining6mo") # for viallabel_to_pid, list_available_data
# load all DEA tables 
obj_list = list_available_data(package="MotrpacRatTraining6moData")
metab_dea = obj_list[grepl("^METAB_",obj_list) & grepl("_DA$",obj_list)]
dea_list = list()
for(dea in metab_dea){
  load(sprintf("../../data/%s.rda", dea))
  dea_list[[dea]] = as.data.table(get(dea))
}
dea = rbindlist(dea_list)
map = unique(dea[,.(feature, tissue, feature_ID, dataset, metabolite_refmet, metabolite)])
table(map[,feature_ID] == map[,metabolite]) # feature_ID is metabolite name 
METAB_FEATURE_ID_MAP = map
setnames(METAB_FEATURE_ID_MAP, c("feature_ID","metabolite"), c("feature_ID_da", "metabolite_name"))
differential_features = unique(TRAINING_REGULATED_FEATURES$feature)
```

# 5. Make "flat" version of normalized data and metabolite metadata 
```{r}
data_list = list()
feature_meta_list = list()
for(i in 1:nrow(METAB_SAMPLE_DATA_NESTED)){
  tissue_code = METAB_SAMPLE_DATA_NESTED$tissue[i]
  tissue = TISSUE_CODE_TO_ABBREV[[tissue_code]]
  assay_code = METAB_SAMPLE_DATA_NESTED$assay_code[i]
  sample_data = as.data.frame(METAB_SAMPLE_DATA_NESTED$sample_data[i][[1]])
  
  # replace colname with pid 
  colnames(sample_data) = viallabel_to_pid(colnames(sample_data))
  feature_IDs = rownames(sample_data)
  
  # make original and "fixed" feature for ALL feature_ID
  features = sprintf("METAB;%s;%s", tissue, feature_IDs)
  new_features = sprintf("METAB;%s;%s:%s", tissue, assay_code, feature_IDs)
  # make data.table
  dt = as.data.table(cbind(feature=features, 
                           new_feature=new_features, 
                           feature_ID=feature_IDs,
                           tissue=tissue,
                           assay="METAB",
                           dataset=assay_code,
                           sample_data))
  label=sprintf("%s;%s", tissue, assay_code)
  data_list[[i]] = dt
  
  feature_meta_list[[i]] = data.table(cbind(tissue = METAB_SAMPLE_DATA_NESTED[i, "tissue"],
                                    assay_code = METAB_SAMPLE_DATA_NESTED[i, "assay_code"],
                                    as.data.table(METAB_SAMPLE_DATA_NESTED[i, "feature_metadata"][[1]])))
  writeLines(label)
  
}
metab_data = rbindlist(data_list, fill=T)
feature_meta = rbindlist(feature_meta_list)
# fix duplicate feature names for differential metabolites 
rep_feat = data.table(REPEATED_FEATURES)
metab_data[,feature := ifelse(new_feature %in% rep_feat[,new_feature], new_feature, feature)]
metab_data[,new_feature := NULL]
# remove "feature" if it's not DE
metab_data[!feature %in% differential_features, feature := NA]
```

```{r}
# do all metabolite names overlap?
table(metab_data[,feature_ID] %in% METAB_FEATURE_ID_MAP[,feature_ID_da])
# all but one:
missing = metab_data[!feature_ID %in% METAB_FEATURE_ID_MAP[,feature_ID_da],feature_ID]
# is it there without the space?
gsub(" $","",missing) %in% METAB_FEATURE_ID_MAP[,feature_ID_da]
# rename feature 
metab_data[feature_ID == missing]
metab_data[feature_ID == missing, feature_ID := gsub(" $","",feature_ID)]
metab_data[feature_ID == gsub(" $","",missing) & tissue == "WAT-SC"]
table(metab_data[,feature_ID] %in% METAB_FEATURE_ID_MAP[,feature_ID_da])
table(METAB_FEATURE_ID_MAP[,feature_ID_da] %in% metab_data[,feature_ID])
# so now all feature_ID overlap between sample-level data and DA tables 
METAB_FEATURE_ID_MAP[,feature_ID_sample_data := feature_ID_da]
```

Now add meta-regression feature ID. 
```{r}
# load all meta-regression DEA tables 
obj_list = list_available_data(package="MotrpacRatTraining6moData")
metab_mr = obj_list[grepl("^METAB_",obj_list) & grepl("_DA_METAREG$",obj_list)]
dea_list = list()
for(dea in metab_mr){
  load(sprintf("../../data/%s.rda", dea))
  dea_list[[dea]] = as.data.table(get(dea))
}
metareg = rbindlist(dea_list)
metareg = unique(metareg[,.(feature, tissue, feature_ID, dataset, metabolite_refmet, metabolite)])
# is refmet NA for any?
table(is.na(metareg[,metabolite_refmet]))
## this is now fixed in an upstream script 
# metareg[is.na(metabolite_refmet)]
# METAB_FEATURE_ID_MAP[feature_ID_da=="TG(36:1)>TG(4:0_16:0_16:1)_and_TG(2:0_16:0_18:1)_feature4"]
# # can we get the refmet from the feature metadata?
# head(feature_meta)
# feature_meta[metabolite_name == "TG(36:1)>TG(4:0_16:0_16:1)_and_TG(2:0_16:0_18:1)_feature4"] # no 
# # how about from MotrpacBicQC?
# head(metabolomics_data_dictionary)
mdd = data.table(metabolomics_data_dictionary)
# mdd[metabolite_name == "TG(36:1)>TG(4:0_16:0_16:1)_and_TG(2:0_16:0_18:1)_feature4 "]
# # yes! 
# # add it to map and metareg and DA
refmet = mdd[metabolite_name == "TG(36:1)>TG(4:0_16:0_16:1)_and_TG(2:0_16:0_18:1)_feature4 ",refmet_name]
METAB_FEATURE_ID_MAP[metabolite_name == "TG(36:1)>TG(4:0_16:0_16:1)_and_TG(2:0_16:0_18:1)_feature4", metabolite_refmet := refmet] 
# metareg[feature_ID == "TG(36:1)>TG(4:0_16:0_16:1)_and_TG(2:0_16:0_18:1)_feature4", metabolite_refmet := refmet]
# 
# data("METAB_WATSC_DA_METAREG")
# METAB_WATSC_DA_METAREG$metabolite_refmet[METAB_WATSC_DA_METAREG$feature_ID == "TG(36:1)>TG(4:0_16:0_16:1)_and_TG(2:0_16:0_18:1)_feature4"] = "TG(36:1)_lp_d"
# # save
# use_data(METAB_WATSC_DA_METAREG, overwrite=T)
# 
# data("METAB_WATSC_DA")
# METAB_WATSC_DA$metabolite_refmet[METAB_WATSC_DA$feature_ID == "TG(36:1)>TG(4:0_16:0_16:1)_and_TG(2:0_16:0_18:1)_feature4"] = "TG(36:1)_lp_d"
# # save
# use_data(METAB_WATSC_DA, overwrite=T)
# now add metareg feature
head(metareg)
head(METAB_FEATURE_ID_MAP)
metareg[,metabolite := NULL]
metareg[is.na(metabolite_refmet)]
# make "feature" column for placeholder
metareg[is.na(feature), feature := sprintf("METAB;%s;%s", tissue, feature_ID)]
METAB_FEATURE_ID_MAP[is.na(feature), feature := sprintf("METAB;%s;%s", tissue, feature_ID_da)]
table(metareg[,feature] %in% METAB_FEATURE_ID_MAP[,feature])
table(metareg[!feature %in% METAB_FEATURE_ID_MAP[,feature], dataset])
# so all features in the meta-regression tables not yet in the feature ID map are from meta-regression 
# this means that multiple features in METAB_FEATURE_ID_MAP will have the same feature_ID_metareg
METAB_FEATURE_ID_MAP[metabolite_refmet == "Adenosine" & tissue == "BAT"]
METAB_FEATURE_ID_MAP[,id := 1:nrow(METAB_FEATURE_ID_MAP)]
# merge in two steps 
setnames(metareg, c("feature_ID"), c("feature_ID_metareg"))
# 1. feature in METAB_FEATURE_ID_MAP
m1 = merge(METAB_FEATURE_ID_MAP, metareg[dataset!="meta-reg"], by=c('feature','metabolite_refmet','dataset','tissue'), all.y=T)
m2 = merge(METAB_FEATURE_ID_MAP, metareg[dataset=="meta-reg"], by=c("tissue","metabolite_refmet"), all.y=T)
setnames(m2, c("feature.x","dataset.x","feature.y","dataset.y"), c("feature","dataset","feature_metareg","dataset_metareg"))
m1[,feature_metareg := feature]
m1[,dataset_metareg := dataset]
merged = rbindlist(list(m1, m2), use.names=T)
# what are we missing?
missing = METAB_FEATURE_ID_MAP[!id %in% merged[,id]]
nrow(missing)
missing
merged[!complete.cases(merged)]
# these 112 cases didn't make it through meta-regression 
# add them to the MAP 
merged = rbindlist(list(merged, missing), fill=T)
METAB_FEATURE_ID_MAP[!id %in% merged[,id]]
METAB_FEATURE_ID_MAP = merged
METAB_FEATURE_ID_MAP[,id := NULL]
# remove "feature" for non-differential features
METAB_FEATURE_ID_MAP[!feature %in% differential_features, feature := NA]
METAB_FEATURE_ID_MAP[!feature_metareg %in% differential_features, feature_metareg := NA]
# are there ever different feature for the same feature?
METAB_FEATURE_ID_MAP[!is.na(feature) & !is.na(feature_metareg) & feature != feature_metareg]
METAB_FEATURE_ID_MAP[metabolite_refmet == "sn-Glycero-3-phosphocholine" & tissue == "WAT-SC"]
metareg[feature_ID_metareg == "sn-Glycero-3-phosphocholine" & tissue == "WAT-SC"]
differential_features[grepl("METAB;WAT-SC;sn-glycero-3-phosphocholine", differential_features, ignore.case = T)]
# both the platform result and the meta-reg result are differential? do we ever include both sets of results?
# for this single case, save both sets of results
standard = METAB_FEATURE_ID_MAP[feature == "METAB;WAT-SC;sn-glycero-3-phosphocholine"]
standard[,feature_metareg := NULL]
standard[,dataset_metareg := dataset]
metareg1 = METAB_FEATURE_ID_MAP[feature_metareg == "METAB;WAT-SC;sn-Glycero-3-phosphocholine"]
metareg1[,feature := NULL]
setnames(metareg1, "feature_metareg", "feature")
METAB_FEATURE_ID_MAP = METAB_FEATURE_ID_MAP[is.na(feature) | feature != "METAB;WAT-SC;sn-glycero-3-phosphocholine"]
METAB_FEATURE_ID_MAP = METAB_FEATURE_ID_MAP[is.na(feature_metareg) | feature_metareg != "METAB;WAT-SC;sn-Glycero-3-phosphocholine"]
METAB_FEATURE_ID_MAP[is.na(feature) & !is.na(feature_metareg), feature := feature_metareg]
METAB_FEATURE_ID_MAP[,feature_metareg := NULL]
METAB_FEATURE_ID_MAP = rbindlist(list(METAB_FEATURE_ID_MAP, standard, metareg1), use.names=T)
backup = copy(METAB_FEATURE_ID_MAP)
```

```{r save flat data}
METAB_FEATURE_ID_MAP = as.data.frame(METAB_FEATURE_ID_MAP[,.(metabolite_name, metabolite_refmet, tissue, dataset,
                                                             feature_ID_sample_data, feature_ID_da, feature_ID_metareg,
                                                             dataset_metareg, feature)])
# merge with feature meta 
head(feature_meta)
feature_meta[,tissue := TISSUE_CODE_TO_ABBREV[tissue]]
feature_meta[,refmet_name := NULL]
table(feature_meta[,metabolite_name] %in% METAB_FEATURE_ID_MAP$feature_ID_sample_data)
table(METAB_FEATURE_ID_MAP$feature_ID_sample_data %in% feature_meta[,metabolite_name])
METAB_FEATURE_ID_MAP$feature_ID_sample_data[! METAB_FEATURE_ID_MAP$feature_ID_sample_data %in% feature_meta[,metabolite_name]]
# does mdd have meta for this feature?
head(mdd)
mdd[metabolite_name == "TG(36:1)>TG(4:0_16:0_16:1)_and_TG(2:0_16:0_18:1)_feature4 "]
missing = data.table(tissue = "WAT-SC",
                     assay_code = "metab-u-lrppos",
                     metabolite_name = "TG(36:1)>TG(4:0_16:0_16:1)_and_TG(2:0_16:0_18:1)_feature4",
                     formula = "C39H72O6")
feature_meta = rbindlist(list(feature_meta, missing), fill=T)
METAB_FEATURE_ID_MAP = merge(METAB_FEATURE_ID_MAP, feature_meta, 
                             by.x=c("tissue","dataset","metabolite_name"), 
                             by.y=c("tissue","assay_code","metabolite_name"),
                             all.x=TRUE)
METAB_FEATURE_ID_MAP[is.na(METAB_FEATURE_ID_MAP$rt),]
# woohoo!
use_data(METAB_FEATURE_ID_MAP, overwrite = TRUE)
table(metab_data[,feature_ID] %in% METAB_FEATURE_ID_MAP$feature_ID_sample_data)
METAB_NORM_DATA_FLAT = as.data.frame(metab_data)
use_data(METAB_NORM_DATA_FLAT, overwrite = TRUE)
sinew::makeOxygen(METAB_FEATURE_ID_MAP)
sinew::makeOxygen(METAB_NORM_DATA_FLAT)
```
